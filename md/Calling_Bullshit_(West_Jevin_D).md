#### Calling Bullshit (West, Jevin D.)
      THE WORLD IS AWASH WITH BULLSHIT, AND WE’RE DROWNING IN IT. Politicians are unconstrained by facts. Science is conducted by press release. Silicon Valley startups elevate bullshit to high art. Colleges and universities reward bullshit over analytic thought. The majority of administrative activity seems to be little more than a sophisticated exercise in the combinatorial reassembly of bullshit.

      One of the most salient features of our culture is that there is so much bullshit. Everyone knows this. Each of us contributes his share. But we tend to take the situation for granted [yet] we have no clear understanding of what bullshit is, why there is so much of it, or what functions it serves. And we lack a conscientiously developed appreciation of what it means to us. In other words, we have no theory.

      Nothing that you will learn in the course of your studies will be of the slightest possible use to you [thereafter], save only this, that if you work hard and intelligently you should be able to detect when a man is talking rot, and that, in my view, is the main, if not the sole, purpose of education.

      In one of his Socratic dialogues, Euthydemus, Plato complains that the philosophers known as the Sophists are indifferent to what is actually true and are interested only in winning arguments. In other words, they are bullshit artists.

      An important genre of bullshit known as weasel wording uses the gap between literal meaning and implicature to avoid taking responsibility for things.

      “The amount of energy needed to refute bullshit is an order of magnitude bigger than [that needed] to produce it.”

      The invention of new and various kinds of communication has given a voice and an audience to many people whose opinions would otherwise not be solicited, and who, in fact, have little else but verbal excrement to contribute to public issues.

      If you can negate a sentence and its meaning doesn’t change, it’s bullshit.

      Bullshit involves language, statistical figures, data graphics, and other forms of presentation intended to persuade or impress an audience by distracting, overwhelming, or intimidating them with a blatant disregard for truth, logical coherence, or what information is actually being conveyed.

      So I gave my lecture yesterday. Despite a lack of preparation, I spoke quite well and without hesitation, which I ascribe to the cocaine I had taken beforehand.

      Unfortunately, one of the most frequent misuses of data, particularly in the popular press, is to suggest a cause-and-effect relationship based on correlation alone.

      There is a key distinction between a probabilistic cause (A increases the chance of B in a causal manner), a sufficient cause (if A happens, B always happens), and a necessary cause (unless A happens, B can’t happen).

      Numbers are ideal vehicles for promulgating bullshit. They feel objective, but are easily manipulated to tell whatever story one desires.

      They estimate that, for one year, in people aged 15−95 years, drinking one alcoholic drink a day increases the risk of developing one of the 23 alcohol-related health problems by 0.5%, compared with not drinking at all.

      This problem is canonized in a principle known as Goodhart’s law. While Goodhart’s original formulation is a bit opaque,fn8 anthropologist Marilyn Strathern rephrased it clearly and concisely: When a measure becomes a target, it ceases to be a good measure.

      At around the same time that Goodhart proposed his law, psychologist Donald Campbell independently proposed an analogous principle: The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor.

      Selection bias arises when the individuals that you sample for your study differ systematically from the population of individuals eligible for your study.

      Our friend applied one of the most important rules for spotting bullshit: If something seems too good or too bad to be true, it probably is.

      They find, indeed, that most users have fewer friends than their friends. In fact, this is the case for 93 percent of Facebook users! Mind twisting, right? These researchers found that the Facebook users have, on average, 190 friends, but their friends have, on average, about 635 friends.

      Observation selection effects explain some of what we typically attribute to bad luck. If you commute by bus on a regular basis, you have probably noticed that you often have to wait a surprisingly long time for the next bus to arrive.

      Once you start thinking about Berkson’s paradox, you’ll see it all over the place.

      This highlights one of the principles for calling bullshit that we espouse. Never assume malice or mendacity when incompetence is a sufficient explanation, and never assume incompetence when a reasonable mistake can explain things.

      In the story we’ve just told, your argument is not sophistry; it is correct. If your client had been found simply by scanning through the FBI’s database until a match was made, there would be something like a five in six chance that he did not leave the fingerprint.fn3

      This confusion is so common that it has its own name, the prosecutor’s fallacy. Our story illustrates why. It can be a matter of life and death in the courtroom, but it’s also a common source of confusion when interpreting the results of scientific studies.

      A p-value describes the probability of getting data at least as extreme as those observed, if the null hypothesis were true. Unlike the prosecutor, scientists aren’t trying to trick anybody when they report this. Scientists are stuck using p-values because they don’t have a good way to calculate the probability of the alternative hypothesis.

      You want to know the chance that someone who tests positive has Lyme disease. It turns out that this is a low probability, because Lyme disease is quite rare. In areas where it is endemic, only about one person out of one thousand is infected. So imagine testing 10,000 people. You’d expect to have about 10 true positives, and about 0.05 × 10,000 = 500 false positives. Fewer than 1 in 50 of those who test positive are actually infected. Thus you expect your patient would have less than a 2 percent

      This confusion—thinking that there is an about 95 percent chance that the patient is infected when actually the chances are less than 2 percent—should be a familiar mistake. This is our old friend, the prosecutor’s fallacy, dressed up in new clothes. We sometimes call it the base rate fallacy because it involves ignoring the base rate of the disease in a population when interpreting the results of a test.

      Our susceptibility to confirmation bias can be seen as falling under the umbrella of sociologist Neil Postman’s dictum, “At any given time, the chief source of bullshit with which you have to contend is yourself.”

      Keep it simple. One advantage that falsehood has over truth is that the truth is often complicated whereas falsehoods can be crafted to be simple. Look for ways to make your story as simple as possible without distorting it. Focus on your core points and let the rest go. Scoring rhetorical points on tangential technicalities doesn’t convince anyone, it just pisses people off.

      Find common ground. The less antagonistic your interaction is, the more likely someone will seriously consider your ideas.

      Don’t impute malice when incompetence is a sufficient explanation. Most people who write foolish things on the Internet or anywhere else do not have a nefarious underlying motive. They simply don’t know what they are talking about.

      Don’t assume incompetence when an honest mistake can account for error. We all make honest mistakes and say stupid things at times; it doesn’t mean that we are stupid or that we are incompetent.

