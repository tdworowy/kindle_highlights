#### Complexity (Mitchell, Melanie)
      Now I can propose a definition of the term complex system: a system in which large networks of components with no central control and simple rules of operation give rise to complex collective behavior, sophisticated information processing, and adaptation via learning or evolution.

      Systems in which organized behavior arises without an internal or external controller or leader are sometimes called self-organizing. Since simple rules produce complex behavior in hard-to-predict ways, the macroscopic behavior of such systems is sometimes called emergent. Here is an alternative definition of a complex system: a system that exhibits nontrivial emergent and self-organizing behaviors.

      Seemingly random behavior can emerge from deterministic systems, with no external source of randomness. The behavior of some simple, deterministic systems can be impossible, even in principle, to predict in the long term, due to sensitive dependence on initial conditions.

      Although the detailed behavior of a chaotic system cannot be predicted, there is some “order in chaos” seen in universal properties common to large sets of chaotic systems, such as the period-doubling route to chaos and Feigenbaum’s constant. Thus even though “prediction becomes impossible” at the detailed level, there are some higher-level aspects of chaotic systems that are indeed predictable.

      Entropy is a measure of the energy that cannot be converted into additional work. The term “entropy” comes from another Greek word—“trope”—meaning “turning into” or “transformation.”

      Turing’s proof of the uncomputability of the Halting problem, sketched above, uses precisely the same core idea as Gödel’s incompleteness proof. Gödel figured out a way to encode mathematical statements so that they could talk about themselves. Turing figured out a way to encode mathematical statements as Turing machines and thus run on one another.

      Natural selection is the major mechanism of evolutionary change and adaptation.

      Evolution is a gradual process, occurring via natural selection on very small random variations in individuals. Variation of this sort is highly abundant in populations and is not biased in any direction (e.g., it does not intrinsically lead to “improvement,” as believed by Lamarck). The source of individual variation is random genetic mutations and recombinations. Macroscale phenomena, such as the origin of new species, can be explained by the microscopic process of gene variation and natural selection.

      Furthermore, Gould and his colleagues attacked the third pillar of the Synthesis by proposing that some of the large-scale phenomena of evolution cannot be explained

      “The [IAS] School of Mathematics has a permanent establishment which is divided into three groups, one consisting of pure mathematics, one consisting of theoretical physicists, and one consisting of Professor von Neumann.”

      Wolfram’s proposed principle consists of four parts: The proper way to think about processes in nature is that they are computing. Since even very simple rules (or “programs”) such as Rule 110 can support universal computation, the ability to support universal computation is very common in nature. Universal computation is an upper limit on the complexity of computations in nature. That is, no natural system or process can produce behavior that is “noncomputable.” The computations done by different processes in nature are almost always equivalent in sophistication.

